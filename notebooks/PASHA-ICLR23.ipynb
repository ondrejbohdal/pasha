{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e400615e-3e2b-4410-9f56-03461c6900bc",
   "metadata": {},
   "source": [
    "# PASHA: Efficient HPO with Progressive Resource Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3b015b-603e-4c19-863f-b91d1291a613",
   "metadata": {},
   "source": [
    "Hyperparameter optimization (HPO) and neural architecture search (NAS) are methods of choice to obtain the best-in-class machine learning models, but in practice they can be costly to run. When models are trained on large datasets, tuning them with HPO or NAS rapidly becomes prohibitively expensive for practitioners, even when efficient multi-fidelity methods are employed. We propose an approach to tackle the challenge of tuning machine learning models trained on large datasets with limited computational resources. Our approach, named PASHA, extends ASHA and is able to dynamically allocate maximum resources for the tuning procedure depending on the need. The experimental comparison shows that PASHA identifies well-performing hyperparameter configurations and architectures while consuming significantly fewer computational resources than ASHA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2112eca-63c9-4b13-8cb0-fd3864675191",
   "metadata": {},
   "source": [
    "Outline:\n",
    "* Initial pre-processing and exploration\n",
    "* Main experiments on NASBench201- with PASHA, ASHA and the baselines\n",
    "* Alternative ranking functions\n",
    "* Changes to the reduction factor\n",
    "* Combination with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2c80fa-5268-49d7-9ebc-0bd4c52f2dbf",
   "metadata": {},
   "source": [
    "Start by importing the relevant libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba934ed4-2655-4ec2-97f7-1106c29171a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.left'] = False\n",
    "\n",
    "from syne_tune.blackbox_repository import load_blackbox\n",
    "from syne_tune.blackbox_repository.simulated_tabular_backend import BlackboxRepositoryBackend\n",
    "from benchmarking.definitions.definition_nasbench201 import (\n",
    "    nasbench201_benchmark,\n",
    "    nasbench201_default_params\n",
    ")\n",
    "from syne_tune.backend.simulator_backend.simulator_callback import SimulatorCallback\n",
    "from syne_tune.optimizer.schedulers.hyperband import HyperbandScheduler\n",
    "from syne_tune.optimizer.baselines import baselines_dict\n",
    "from syne_tune.tuner import Tuner\n",
    "from syne_tune.stopping_criterion import StoppingCriterion\n",
    "from syne_tune.experiments import load_experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b685b1-824d-477e-a9e3-ecbc06d19adf",
   "metadata": {},
   "source": [
    "Define our settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "409df06e-280d-4a87-8afe-40a7db28e13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_valid_error_dim = 0\n",
    "metric_runtime_dim = 2\n",
    "dataset_names = ['cifar10', 'cifar100', 'ImageNet16-120']\n",
    "epoch_names = ['val_acc_epoch_' + str(e) for e in range(200)]\n",
    "random_seeds = [31415927, 0, 1234, 3458, 7685]\n",
    "nb201_random_seeds = [0, 1, 2]\n",
    "n_workers = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810f0609-63a8-4714-b328-9489c601ef9a",
   "metadata": {},
   "source": [
    "# Initial pre-processing and exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f2cd7e-c425-47eb-88c1-3fd5a248d8bd",
   "metadata": {},
   "source": [
    "Load NASBench201 benchmark so that we can analyse the performance of various approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f33be501-3945-4603-9521-4d65a4404145",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_dict = {}\n",
    "for dataset in dataset_names:\n",
    "    bb_dict[dataset] = load_blackbox(dataset)[dataset]\n",
    "\n",
    "df_dict = {}\n",
    "\n",
    "for seed in nb201_random_seeds:\n",
    "    df_dict[seed] = {}\n",
    "    for dataset in dataset_names:\n",
    "        # create a dataframe with the validation accuracies for various epochs\n",
    "        df_val_acc = pd.DataFrame((1.0-bb_dict[dataset].objectives_evaluations[:, seed, :, metric_valid_error_dim])\n",
    "                                  * 100, columns=['val_acc_epoch_' + str(e) for e in range(200)])\n",
    "\n",
    "        # add a new column with the best validation accuracy\n",
    "        df_val_acc['val_acc_best'] = df_val_acc[epoch_names].max(axis=1)\n",
    "        # create a dataframe with the hyperparameter values\n",
    "        df_hp = bb_dict[dataset].hyperparameters\n",
    "        # create a dataframe with the times it takes to run an epoch\n",
    "        df_time = pd.DataFrame(bb_dict[dataset].objectives_evaluations[:, seed, :, metric_runtime_dim][:, -1], columns=['eval_time_epoch'])    \n",
    "        # combine all smaller dataframes into one dataframe for each NASBench201 random seed and dataset\n",
    "        df_dict[seed][dataset] = pd.concat([df_hp, df_val_acc, df_time], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7cc4d8-0c4c-420b-9b2c-a1332c720b39",
   "metadata": {},
   "source": [
    "Motivation to measure best validation accuracy: NASBench201 provides validation and test errors in an inconsistent format and in fact we can only get the errors for each epoch on their combined validation and test sets for CIFAR-100 and ImageNet16-120. As a trade-off, we use the combined validation and test sets as the validation set. Consequently, there is no test set which we can use for additional evaluation and so we use the best validation accuracy as the final evaluation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c32d92-6939-4cba-aa48-405f6df00cd8",
   "metadata": {},
   "source": [
    "Have a look at what the dataframes look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10be535e-5ea5-431c-a2fa-6586f0d45a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hp_x0</th>\n",
       "      <th>hp_x1</th>\n",
       "      <th>hp_x2</th>\n",
       "      <th>hp_x3</th>\n",
       "      <th>hp_x4</th>\n",
       "      <th>hp_x5</th>\n",
       "      <th>val_acc_epoch_0</th>\n",
       "      <th>val_acc_epoch_1</th>\n",
       "      <th>val_acc_epoch_2</th>\n",
       "      <th>val_acc_epoch_3</th>\n",
       "      <th>...</th>\n",
       "      <th>val_acc_epoch_192</th>\n",
       "      <th>val_acc_epoch_193</th>\n",
       "      <th>val_acc_epoch_194</th>\n",
       "      <th>val_acc_epoch_195</th>\n",
       "      <th>val_acc_epoch_196</th>\n",
       "      <th>val_acc_epoch_197</th>\n",
       "      <th>val_acc_epoch_198</th>\n",
       "      <th>val_acc_epoch_199</th>\n",
       "      <th>val_acc_best</th>\n",
       "      <th>eval_time_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avg_pool_3x3</td>\n",
       "      <td>nor_conv_1x1</td>\n",
       "      <td>skip_connect</td>\n",
       "      <td>nor_conv_1x1</td>\n",
       "      <td>skip_connect</td>\n",
       "      <td>skip_connect</td>\n",
       "      <td>37.980003</td>\n",
       "      <td>36.909996</td>\n",
       "      <td>38.739998</td>\n",
       "      <td>31.059998</td>\n",
       "      <td>...</td>\n",
       "      <td>85.469994</td>\n",
       "      <td>85.479996</td>\n",
       "      <td>85.699997</td>\n",
       "      <td>85.689995</td>\n",
       "      <td>85.570000</td>\n",
       "      <td>85.639999</td>\n",
       "      <td>85.659996</td>\n",
       "      <td>85.619995</td>\n",
       "      <td>85.729996</td>\n",
       "      <td>15.461778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nor_conv_3x3</td>\n",
       "      <td>nor_conv_3x3</td>\n",
       "      <td>avg_pool_3x3</td>\n",
       "      <td>skip_connect</td>\n",
       "      <td>nor_conv_3x3</td>\n",
       "      <td>skip_connect</td>\n",
       "      <td>34.619999</td>\n",
       "      <td>61.129997</td>\n",
       "      <td>61.039997</td>\n",
       "      <td>70.029999</td>\n",
       "      <td>...</td>\n",
       "      <td>93.739998</td>\n",
       "      <td>93.739998</td>\n",
       "      <td>93.729996</td>\n",
       "      <td>93.709999</td>\n",
       "      <td>93.739998</td>\n",
       "      <td>93.729996</td>\n",
       "      <td>93.639999</td>\n",
       "      <td>93.750000</td>\n",
       "      <td>93.750000</td>\n",
       "      <td>23.198093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avg_pool_3x3</td>\n",
       "      <td>nor_conv_3x3</td>\n",
       "      <td>nor_conv_3x3</td>\n",
       "      <td>avg_pool_3x3</td>\n",
       "      <td>avg_pool_3x3</td>\n",
       "      <td>avg_pool_3x3</td>\n",
       "      <td>36.389999</td>\n",
       "      <td>44.279999</td>\n",
       "      <td>42.290001</td>\n",
       "      <td>42.139999</td>\n",
       "      <td>...</td>\n",
       "      <td>86.029999</td>\n",
       "      <td>85.790001</td>\n",
       "      <td>85.820000</td>\n",
       "      <td>85.959999</td>\n",
       "      <td>85.870003</td>\n",
       "      <td>85.699997</td>\n",
       "      <td>85.769997</td>\n",
       "      <td>85.839996</td>\n",
       "      <td>86.029999</td>\n",
       "      <td>24.261475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avg_pool_3x3</td>\n",
       "      <td>skip_connect</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>skip_connect</td>\n",
       "      <td>37.349998</td>\n",
       "      <td>48.919998</td>\n",
       "      <td>56.320000</td>\n",
       "      <td>59.029995</td>\n",
       "      <td>...</td>\n",
       "      <td>86.870003</td>\n",
       "      <td>86.779999</td>\n",
       "      <td>86.790001</td>\n",
       "      <td>86.830002</td>\n",
       "      <td>86.870003</td>\n",
       "      <td>86.720001</td>\n",
       "      <td>86.790001</td>\n",
       "      <td>86.809998</td>\n",
       "      <td>86.989998</td>\n",
       "      <td>9.305114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>skip_connect</td>\n",
       "      <td>skip_connect</td>\n",
       "      <td>nor_conv_1x1</td>\n",
       "      <td>skip_connect</td>\n",
       "      <td>skip_connect</td>\n",
       "      <td>nor_conv_1x1</td>\n",
       "      <td>35.450001</td>\n",
       "      <td>36.369999</td>\n",
       "      <td>32.860001</td>\n",
       "      <td>34.069996</td>\n",
       "      <td>...</td>\n",
       "      <td>87.900002</td>\n",
       "      <td>88.199997</td>\n",
       "      <td>88.160004</td>\n",
       "      <td>88.099998</td>\n",
       "      <td>87.989998</td>\n",
       "      <td>88.070000</td>\n",
       "      <td>88.209999</td>\n",
       "      <td>88.090004</td>\n",
       "      <td>88.209999</td>\n",
       "      <td>13.933862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15620</th>\n",
       "      <td>none</td>\n",
       "      <td>avg_pool_3x3</td>\n",
       "      <td>avg_pool_3x3</td>\n",
       "      <td>skip_connect</td>\n",
       "      <td>skip_connect</td>\n",
       "      <td>none</td>\n",
       "      <td>40.399998</td>\n",
       "      <td>47.910000</td>\n",
       "      <td>58.350002</td>\n",
       "      <td>56.389999</td>\n",
       "      <td>...</td>\n",
       "      <td>86.449997</td>\n",
       "      <td>86.529999</td>\n",
       "      <td>86.489998</td>\n",
       "      <td>86.660004</td>\n",
       "      <td>86.639999</td>\n",
       "      <td>86.669998</td>\n",
       "      <td>86.559998</td>\n",
       "      <td>86.619995</td>\n",
       "      <td>86.669998</td>\n",
       "      <td>11.035928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15621</th>\n",
       "      <td>avg_pool_3x3</td>\n",
       "      <td>nor_conv_3x3</td>\n",
       "      <td>nor_conv_3x3</td>\n",
       "      <td>skip_connect</td>\n",
       "      <td>nor_conv_1x1</td>\n",
       "      <td>none</td>\n",
       "      <td>36.619995</td>\n",
       "      <td>51.030003</td>\n",
       "      <td>60.530003</td>\n",
       "      <td>45.649998</td>\n",
       "      <td>...</td>\n",
       "      <td>88.489998</td>\n",
       "      <td>88.459999</td>\n",
       "      <td>88.700005</td>\n",
       "      <td>88.610001</td>\n",
       "      <td>88.510002</td>\n",
       "      <td>88.510002</td>\n",
       "      <td>88.669998</td>\n",
       "      <td>88.400002</td>\n",
       "      <td>88.700005</td>\n",
       "      <td>22.097097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15622</th>\n",
       "      <td>skip_connect</td>\n",
       "      <td>nor_conv_3x3</td>\n",
       "      <td>nor_conv_3x3</td>\n",
       "      <td>nor_conv_3x3</td>\n",
       "      <td>none</td>\n",
       "      <td>nor_conv_1x1</td>\n",
       "      <td>37.989998</td>\n",
       "      <td>45.160000</td>\n",
       "      <td>48.240002</td>\n",
       "      <td>55.739998</td>\n",
       "      <td>...</td>\n",
       "      <td>92.779999</td>\n",
       "      <td>92.769997</td>\n",
       "      <td>92.809998</td>\n",
       "      <td>92.750000</td>\n",
       "      <td>92.720001</td>\n",
       "      <td>92.729996</td>\n",
       "      <td>92.769997</td>\n",
       "      <td>92.779999</td>\n",
       "      <td>92.849998</td>\n",
       "      <td>24.775816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15623</th>\n",
       "      <td>none</td>\n",
       "      <td>avg_pool_3x3</td>\n",
       "      <td>avg_pool_3x3</td>\n",
       "      <td>avg_pool_3x3</td>\n",
       "      <td>none</td>\n",
       "      <td>avg_pool_3x3</td>\n",
       "      <td>20.420002</td>\n",
       "      <td>29.619997</td>\n",
       "      <td>21.740002</td>\n",
       "      <td>25.230003</td>\n",
       "      <td>...</td>\n",
       "      <td>69.110001</td>\n",
       "      <td>68.739998</td>\n",
       "      <td>69.089996</td>\n",
       "      <td>69.330002</td>\n",
       "      <td>69.449997</td>\n",
       "      <td>69.459999</td>\n",
       "      <td>69.420006</td>\n",
       "      <td>69.480003</td>\n",
       "      <td>69.480003</td>\n",
       "      <td>14.217638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15624</th>\n",
       "      <td>nor_conv_1x1</td>\n",
       "      <td>none</td>\n",
       "      <td>nor_conv_1x1</td>\n",
       "      <td>none</td>\n",
       "      <td>nor_conv_1x1</td>\n",
       "      <td>nor_conv_1x1</td>\n",
       "      <td>30.980003</td>\n",
       "      <td>35.140003</td>\n",
       "      <td>38.410004</td>\n",
       "      <td>40.420002</td>\n",
       "      <td>...</td>\n",
       "      <td>85.399994</td>\n",
       "      <td>85.539993</td>\n",
       "      <td>85.430000</td>\n",
       "      <td>85.489998</td>\n",
       "      <td>85.519997</td>\n",
       "      <td>85.659996</td>\n",
       "      <td>85.549995</td>\n",
       "      <td>85.619995</td>\n",
       "      <td>85.659996</td>\n",
       "      <td>22.166279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15625 rows Ã— 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              hp_x0         hp_x1         hp_x2         hp_x3         hp_x4  \\\n",
       "0      avg_pool_3x3  nor_conv_1x1  skip_connect  nor_conv_1x1  skip_connect   \n",
       "1      nor_conv_3x3  nor_conv_3x3  avg_pool_3x3  skip_connect  nor_conv_3x3   \n",
       "2      avg_pool_3x3  nor_conv_3x3  nor_conv_3x3  avg_pool_3x3  avg_pool_3x3   \n",
       "3      avg_pool_3x3  skip_connect          none          none          none   \n",
       "4      skip_connect  skip_connect  nor_conv_1x1  skip_connect  skip_connect   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "15620          none  avg_pool_3x3  avg_pool_3x3  skip_connect  skip_connect   \n",
       "15621  avg_pool_3x3  nor_conv_3x3  nor_conv_3x3  skip_connect  nor_conv_1x1   \n",
       "15622  skip_connect  nor_conv_3x3  nor_conv_3x3  nor_conv_3x3          none   \n",
       "15623          none  avg_pool_3x3  avg_pool_3x3  avg_pool_3x3          none   \n",
       "15624  nor_conv_1x1          none  nor_conv_1x1          none  nor_conv_1x1   \n",
       "\n",
       "              hp_x5  val_acc_epoch_0  val_acc_epoch_1  val_acc_epoch_2  \\\n",
       "0      skip_connect        37.980003        36.909996        38.739998   \n",
       "1      skip_connect        34.619999        61.129997        61.039997   \n",
       "2      avg_pool_3x3        36.389999        44.279999        42.290001   \n",
       "3      skip_connect        37.349998        48.919998        56.320000   \n",
       "4      nor_conv_1x1        35.450001        36.369999        32.860001   \n",
       "...             ...              ...              ...              ...   \n",
       "15620          none        40.399998        47.910000        58.350002   \n",
       "15621          none        36.619995        51.030003        60.530003   \n",
       "15622  nor_conv_1x1        37.989998        45.160000        48.240002   \n",
       "15623  avg_pool_3x3        20.420002        29.619997        21.740002   \n",
       "15624  nor_conv_1x1        30.980003        35.140003        38.410004   \n",
       "\n",
       "       val_acc_epoch_3  ...  val_acc_epoch_192  val_acc_epoch_193  \\\n",
       "0            31.059998  ...          85.469994          85.479996   \n",
       "1            70.029999  ...          93.739998          93.739998   \n",
       "2            42.139999  ...          86.029999          85.790001   \n",
       "3            59.029995  ...          86.870003          86.779999   \n",
       "4            34.069996  ...          87.900002          88.199997   \n",
       "...                ...  ...                ...                ...   \n",
       "15620        56.389999  ...          86.449997          86.529999   \n",
       "15621        45.649998  ...          88.489998          88.459999   \n",
       "15622        55.739998  ...          92.779999          92.769997   \n",
       "15623        25.230003  ...          69.110001          68.739998   \n",
       "15624        40.420002  ...          85.399994          85.539993   \n",
       "\n",
       "       val_acc_epoch_194  val_acc_epoch_195  val_acc_epoch_196  \\\n",
       "0              85.699997          85.689995          85.570000   \n",
       "1              93.729996          93.709999          93.739998   \n",
       "2              85.820000          85.959999          85.870003   \n",
       "3              86.790001          86.830002          86.870003   \n",
       "4              88.160004          88.099998          87.989998   \n",
       "...                  ...                ...                ...   \n",
       "15620          86.489998          86.660004          86.639999   \n",
       "15621          88.700005          88.610001          88.510002   \n",
       "15622          92.809998          92.750000          92.720001   \n",
       "15623          69.089996          69.330002          69.449997   \n",
       "15624          85.430000          85.489998          85.519997   \n",
       "\n",
       "       val_acc_epoch_197  val_acc_epoch_198  val_acc_epoch_199  val_acc_best  \\\n",
       "0              85.639999          85.659996          85.619995     85.729996   \n",
       "1              93.729996          93.639999          93.750000     93.750000   \n",
       "2              85.699997          85.769997          85.839996     86.029999   \n",
       "3              86.720001          86.790001          86.809998     86.989998   \n",
       "4              88.070000          88.209999          88.090004     88.209999   \n",
       "...                  ...                ...                ...           ...   \n",
       "15620          86.669998          86.559998          86.619995     86.669998   \n",
       "15621          88.510002          88.669998          88.400002     88.700005   \n",
       "15622          92.729996          92.769997          92.779999     92.849998   \n",
       "15623          69.459999          69.420006          69.480003     69.480003   \n",
       "15624          85.659996          85.549995          85.619995     85.659996   \n",
       "\n",
       "       eval_time_epoch  \n",
       "0            15.461778  \n",
       "1            23.198093  \n",
       "2            24.261475  \n",
       "3             9.305114  \n",
       "4            13.933862  \n",
       "...                ...  \n",
       "15620        11.035928  \n",
       "15621        22.097097  \n",
       "15622        24.775816  \n",
       "15623        14.217638  \n",
       "15624        22.166279  \n",
       "\n",
       "[15625 rows x 208 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict[0]['cifar10']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a13c2e2-3410-4329-a9f2-2c0d1d3840a6",
   "metadata": {},
   "source": [
    "Perform brief exploratory analysis to show NAS is helpful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42530baf-ed37-4e39-b45c-6668bf291ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(131)\n",
    "plt.hist(df_dict[0]['cifar10']['val_acc_best'], bins=100)\n",
    "plt.xlabel('Best validation accuracy (%)', fontsize=14)\n",
    "plt.title('CIFAR-10', fontsize=16)\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.hist(df_dict[0]['cifar100']['val_acc_best'], bins=100)\n",
    "plt.xlabel('Best validation accuracy (%)', fontsize=14)\n",
    "plt.title('CIFAR-100', fontsize=16)\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.hist(df_dict[0]['ImageNet16-120']['val_acc_best'], bins=100)\n",
    "plt.xlabel('Best validation accuracy (%)', fontsize=14)\n",
    "plt.title('ImageNet16-120', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8b09e9-e9c3-474d-bc3e-7f00e8594e7d",
   "metadata": {},
   "source": [
    "We can clearly see that there is a huge difference between the various configurations, so NAS is important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153714ad-7ac2-403d-943b-495d9f7b9287",
   "metadata": {},
   "source": [
    "## Main experiments\n",
    "We perform experiments on NASBench201 - CIFAR-10, CIFAR-100 and ImageNet16-120 datasets. We use PASHA, ASHA (promotion type) and the relevant baselines - one epoch and random."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f2c1f1-4c5a-4e52-b9e3-05d2cd0c268f",
   "metadata": {},
   "source": [
    "Grace period is the name for minimum resources in SyneTune."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5dfa59-0b03-466d-b91d-95a85c3e7a75",
   "metadata": {},
   "source": [
    "Define functions for running the experiments and analysing them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae6d2cfe-bdc7-4ba5-b143-1de2a5def523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(dataset_name, random_seed, benchmark_random_seed, hpo_approach, reduction_factor=None, rung_system_kwargs={'ranking_criterion': 'soft_ranking', 'epsilon': 0.025}, benchmark_metric='metric_valid_error', benchmark='nasbench201', benchmark_mode=None):\n",
    "    \"\"\"\n",
    "    Function to run an experiment. It is similar to the NASBench201 example script\n",
    "    in syne-tune but extended to make it simple to run our experiments.\n",
    "    \n",
    "    When describing the following parameters we say what values we use, but feel free to also use other values.\n",
    "    \n",
    "    :param dataset_name: one of 'cifar10', 'cifar100', 'ImageNet16-120'\n",
    "    :param random_seed: one of 31415927, 0, 1234, 3458, 7685\n",
    "    :param benchmark_random_seed: one of 0, 1, 2 for nasbench201 and 0 for lcbench\n",
    "    :param hpo_approach: one of 'pasha', 'asha', 'pasha-bo', 'asha-bo'\n",
    "    :param reduction_factor: by default None (resulting in using the default value 3) or 2, 4\n",
    "    :param rung_system_kwargs: dictionary of ranking criterion (str) and epsilon or epsilon scaling (both float)\n",
    "    :return: tuner.name\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # this function is similar to the NASBench201 example script\n",
    "    logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "    default_params = nasbench201_default_params({'backend': 'simulated'})\n",
    "    benchmark = nasbench201_benchmark(default_params)\n",
    "    resource_attr = benchmark['resource_attr']\n",
    "    max_t = default_params['max_resource_level']\n",
    "    blackbox_name = dataset_name\n",
    "    # NASBench201 is a blackbox from the repository\n",
    "    assert blackbox_name is not None\n",
    "    elapsed_time_attr = 'elapsed_time'\n",
    "    surrogate = None\n",
    "        \n",
    "    # benchmark must be tabulated to support simulation\n",
    "    assert benchmark.get('supports_simulated', False)\n",
    "    if benchmark_mode:\n",
    "        mode = benchmark_mode\n",
    "    else:\n",
    "        mode = benchmark['mode']\n",
    "    \n",
    "    metric = benchmark_metric  # benchmark['metric']\n",
    "\n",
    "    config_space = benchmark['config_space']\n",
    "    config_space['dataset_name'] = dataset_name\n",
    "\n",
    "    # simulator back-end specialized to tabulated blackboxes\n",
    "    trial_backend = BlackboxRepositoryBackend(\n",
    "        blackbox_name=blackbox_name,\n",
    "        elapsed_time_attr=elapsed_time_attr,\n",
    "        dataset=dataset_name,\n",
    "        seed=benchmark_random_seed,\n",
    "        surrogate=surrogate)\n",
    "\n",
    "    # set logging of the simulator backend to WARNING level\n",
    "    logging.getLogger('syne_tune.backend.simulator_backend.simulator_backend').setLevel(logging.WARNING)\n",
    "    \n",
    "    if not reduction_factor:\n",
    "        reduction_factor = default_params['reduction_factor']\n",
    "            \n",
    "    # we support various schedulers within the function\n",
    "    # NOTE: previously we used resource_attr instead of max_resource_attr\n",
    "    if hpo_approach == 'pasha':\n",
    "        scheduler = baselines_dict['PASHA'](\n",
    "            config_space,\n",
    "            max_t=max_t,\n",
    "            grace_period=default_params['grace_period'],\n",
    "            reduction_factor=reduction_factor,\n",
    "            resource_attr=resource_attr,\n",
    "            mode=mode,\n",
    "            metric=metric,\n",
    "            random_seed=random_seed,\n",
    "            rung_system_kwargs=rung_system_kwargs)\n",
    "    elif hpo_approach == 'asha':\n",
    "        scheduler = baselines_dict['ASHA'](\n",
    "            config_space,\n",
    "            max_t=max_t,\n",
    "            grace_period=default_params['grace_period'],\n",
    "            reduction_factor=reduction_factor,\n",
    "            resource_attr=resource_attr,\n",
    "            mode=mode,\n",
    "            type='promotion',\n",
    "            metric=metric,\n",
    "            random_seed=random_seed)\n",
    "    elif hpo_approach == 'pasha-bo':\n",
    "        scheduler = HyperbandScheduler(\n",
    "            config_space,\n",
    "            max_t=max_t,\n",
    "            grace_period=default_params['grace_period'],\n",
    "            reduction_factor=reduction_factor,\n",
    "            resource_attr=resource_attr,\n",
    "            mode=mode,\n",
    "            searcher='bayesopt',\n",
    "            type='pasha',\n",
    "            metric=metric,\n",
    "            random_seed=random_seed,\n",
    "            rung_system_kwargs=rung_system_kwargs)\n",
    "    elif hpo_approach == 'asha-bo':\n",
    "        scheduler = HyperbandScheduler(\n",
    "            config_space,\n",
    "            max_t=max_t,\n",
    "            grace_period=default_params['grace_period'],\n",
    "            reduction_factor=reduction_factor,\n",
    "            resource_attr=resource_attr,\n",
    "            mode=mode,\n",
    "            searcher='bayesopt',\n",
    "            type='promotion',\n",
    "            metric=metric,\n",
    "            random_seed=random_seed)\n",
    "    else:\n",
    "        raise ValueError('The selected scheduler is not implemented')\n",
    "\n",
    "    stop_criterion = StoppingCriterion(max_num_trials_started=256)\n",
    "    # printing the status during tuning takes a lot of time, and so does\n",
    "    # storing results\n",
    "    print_update_interval = 7000\n",
    "    results_update_interval = 3000\n",
    "    # it is important to set `sleep_time` to 0 here (mandatory for simulator\n",
    "    # backend)\n",
    "\n",
    "    tuner = Tuner(\n",
    "        trial_backend=trial_backend,\n",
    "        scheduler=scheduler,\n",
    "        stop_criterion=stop_criterion,\n",
    "        n_workers=n_workers,\n",
    "        sleep_time=0,\n",
    "        results_update_interval=results_update_interval,\n",
    "        print_update_interval=print_update_interval,\n",
    "        # this callback is required in order to make things work with the\n",
    "        # simulator callback. It makes sure that results are stored with\n",
    "        # simulated time (rather than real time), and that the time_keeper\n",
    "        # is advanced properly whenever the tuner loop sleeps\n",
    "        callbacks=[SimulatorCallback()],\n",
    "    )\n",
    "    \n",
    "    tuner.run()\n",
    "    \n",
    "    return tuner.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ea790f4-1791-4f98-97e9-bbe67b13b3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_experiments(experiment_names_dict, reference_time=None):\n",
    "    \"\"\"\n",
    "    Function to analyse the experiments that we run with run_experiment function.\n",
    "    \n",
    "    :param experiment_names_dict: dictionary mapping the dataset names to tuples of\n",
    "        experiment names and NASBench201 random seeds\n",
    "    :reference_time: optional argument with the time it takes to run the standard method - e.g. ASHA\n",
    "    :return: tuple of a line to display (string reporting the experiment results) and \n",
    "        the mean of the runtimes that can be used as reference time for other approaches\n",
    "    \"\"\"\n",
    "    val_acc_best_list = []\n",
    "    max_rsc_list = []\n",
    "    runtime_list = []\n",
    "    \n",
    "    for experiment_name, nb201_random_seed in experiment_names_dict[dataset_name]:\n",
    "        experiment_results = load_experiment(experiment_name)\n",
    "        best_cfg = experiment_results.results['metric_valid_error'].argmin()\n",
    "        \n",
    "        # find the best validation accuracy of the corresponding entry in NASBench201\n",
    "        table_hp_names = ['hp_x' + str(hp_idx) for hp_idx in range(6)]\n",
    "        results_hp_names = ['config_hp_x' + str(hp_idx) for hp_idx in range(6)]\n",
    "        condition = (df_dict[nb201_random_seed][dataset_name][table_hp_names] == experiment_results.results[results_hp_names].iloc[best_cfg].tolist()).all(axis=1)\n",
    "        val_acc_best = df_dict[nb201_random_seed][dataset_name][condition]['val_acc_best'].values[0]  # there is only one item in the list\n",
    "        val_acc_best_list.append(val_acc_best)\n",
    "        max_rsc_list.append(experiment_results.results['hp_epoch'].max())\n",
    "        runtime_list.append(experiment_results.results['st_tuner_time'].max())\n",
    "        \n",
    "    line = ' & {:.2f} $\\pm$ {:.2f}'.format(np.mean(val_acc_best_list), np.std(val_acc_best_list))\n",
    "    line += ' & {:.1f}h $\\pm$ {:.1f}h'.format(np.mean(runtime_list)/3600, np.std(runtime_list)/3600)\n",
    "    if reference_time:\n",
    "        line += ' & {:.1f}x'.format(reference_time/np.mean(runtime_list))\n",
    "    else:\n",
    "        line += ' & {:.1f}x'.format(np.mean(runtime_list)/np.mean(runtime_list))\n",
    "    line += ' & {:.1f} $\\pm$ {:.1f}'.format(np.mean(max_rsc_list), np.std(max_rsc_list))\n",
    "    \n",
    "    return line, np.mean(runtime_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a556ca5-1021-4b67-b579-707aaeb6e387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_one_epoch_baseline(metric='val_acc'):\n",
    "    \"\"\"\n",
    "    Function to compute the performance of a simple one epoch baseline.\n",
    "    :return: a line to display (string reporting the experiment results)\n",
    "    \"\"\"\n",
    "    best_val_obj_list = []\n",
    "    total_time_list = []\n",
    "    \n",
    "    for nb201_random_seed in nb201_random_seeds:\n",
    "        for random_seed in random_seeds:\n",
    "            # randomly sample 256 configurations for the given dataset and NASBench201 seed\n",
    "            # use the same seeds as for our other experiments\n",
    "            random.seed(random_seed)\n",
    "            cfg_list = random.sample(range(len(df_dict[nb201_random_seed][dataset_name])), 256)\n",
    "            selected_subset = df_dict[nb201_random_seed][dataset_name].iloc[cfg_list]\n",
    "            # find configuration with the best performance after doing one epoch\n",
    "            max_idx = selected_subset[metric + '_epoch_0'].argmax()\n",
    "            best_configuration = selected_subset.iloc[max_idx]\n",
    "            # find the best validation accuracy of the selected configuration\n",
    "            # as that is the metric that we compare \n",
    "            best_val_obj = best_configuration[epoch_names].max()\n",
    "\n",
    "            # we also need to calculate the time it took for this\n",
    "            # taking into account the number of workers\n",
    "            total_time = selected_subset['eval_time_epoch'].sum() / n_workers\n",
    "\n",
    "            best_val_obj_list.append(best_val_obj)\n",
    "            total_time_list.append(total_time)\n",
    "\n",
    "    line = ' & {:.2f} $\\pm$ {:.2f}'.format(np.mean(best_val_obj_list), np.std(best_val_obj_list))\n",
    "    line += ' & {:.1f}h $\\pm$ {:.1f}h'.format(np.mean(total_time_list)/3600, np.std(total_time_list)/3600)\n",
    "    line += ' & {:.1f}x'.format(reference_time/np.mean(total_time_list))\n",
    "    line += ' & 1.0 $\\pm$ 0.0'\n",
    "\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12640ea4-4932-4c87-8577-bad254eacd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_random_baseline():\n",
    "    \"\"\"\n",
    "    Function to compute the performance of a simple random configuration baseline.\n",
    "    \n",
    "    We consider a ten times larger number of configurations in this case to get a better\n",
    "    estimate of the performance of a random configuration.\n",
    "\n",
    "    :return: a line to display (string reporting the experiment results)\n",
    "    \"\"\"\n",
    "    random.seed(0)\n",
    "    random_seeds_rb = random.sample(range(999999), 256 * 10)\n",
    "\n",
    "    best_val_obj_list = []\n",
    "    total_time_list = []\n",
    "\n",
    "    for nb201_random_seed in nb201_random_seeds:\n",
    "        for random_seed in random_seeds_rb:\n",
    "            random.seed(random_seed)\n",
    "            # select the random configurations\n",
    "            cfg_list = random.sample(range(len(df_dict[nb201_random_seed][dataset_name])), 1)\n",
    "            selected_configuration = df_dict[nb201_random_seed][dataset_name].iloc[cfg_list]\n",
    "            # find the best validation accuracy of the selected configuration\n",
    "            # as that is the metric that we compare \n",
    "            best_val_obj = selected_configuration[epoch_names].max()\n",
    "\n",
    "            # we also need to calculate the time it took for this\n",
    "            total_time = 0.0\n",
    "\n",
    "            best_val_obj_list.append(best_val_obj)\n",
    "            total_time_list.append(total_time)\n",
    "\n",
    "    line = ' & {:.2f} $\\pm$ {:.2f}'.format(np.mean(best_val_obj_list), np.std(best_val_obj_list))\n",
    "    line += ' & {:.1f}h $\\pm$ {:.1f}h'.format(np.mean(total_time_list)/3600, np.std(total_time_list)/3600)\n",
    "    line += ' & NA'\n",
    "    line += ' & 0.0 $\\pm$ 0.0'\n",
    "\n",
    "    return line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3b3def-b25e-42d2-9939-990f67d60e56",
   "metadata": {},
   "source": [
    "Run the main experiments with PASHA, ASHA and the baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "add9dbfc-c2da-47d9-9369-6c4ad8776538",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "experiment_names_asha_val_acc = {dataset: [] for dataset in dataset_names}\n",
    "experiment_names_pasha_val_acc_auto = {dataset: [] for dataset in dataset_names}\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    for nb201_random_seed in nb201_random_seeds:\n",
    "        for random_seed in random_seeds:\n",
    "            experiment_name = run_experiment(dataset_name, random_seed, nb201_random_seed, 'asha', benchmark_metric='metric_valid_error')\n",
    "            experiment_names_asha_val_acc[dataset_name].append((experiment_name, nb201_random_seed))\n",
    "            experiment_name = run_experiment(dataset_name, random_seed, nb201_random_seed, 'pasha', benchmark_metric='metric_valid_error', rung_system_kwargs={'ranking_criterion': 'soft_ranking_auto', 'epsilon': 0.0})\n",
    "            experiment_names_pasha_val_acc_auto[dataset_name].append((experiment_name, nb201_random_seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f35aded-e866-4d43-b4e4-9046fed69370",
   "metadata": {},
   "source": [
    "Analyse the experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "490bdbb7-5ee1-47ae-814f-e3af61471058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar10\n",
      "ASHA VACC & 93.85 $\\pm$ 0.25 & 3.0h $\\pm$ 0.6h & 1.0x & 200.0 $\\pm$ 0.0\n",
      "PASHA VACC-AUTO & 93.57 $\\pm$ 0.75 & 1.3h $\\pm$ 0.6h & 2.3x & 36.1 $\\pm$ 50.0\n",
      "One epoch baseline VACC  & 93.30 $\\pm$ 0.61 & 0.3h $\\pm$ 0.0h & 8.5x & 1.0 $\\pm$ 0.0\n",
      "Random baseline  & 72.93 $\\pm$ 19.55 & 0.0h $\\pm$ 0.0h & NA & 0.0 $\\pm$ 0.0\n",
      "cifar100\n",
      "ASHA VACC & 71.69 $\\pm$ 1.05 & 3.2h $\\pm$ 0.9h & 1.0x & 200.0 $\\pm$ 0.0\n",
      "PASHA VACC-AUTO & 71.84 $\\pm$ 1.41 & 0.9h $\\pm$ 0.4h & 3.4x & 20.5 $\\pm$ 48.3\n",
      "One epoch baseline VACC  & 65.57 $\\pm$ 5.53 & 0.3h $\\pm$ 0.0h & 9.2x & 1.0 $\\pm$ 0.0\n",
      "Random baseline  & 42.98 $\\pm$ 18.34 & 0.0h $\\pm$ 0.0h & NA & 0.0 $\\pm$ 0.0\n",
      "ImageNet16-120\n",
      "ASHA VACC & 45.63 $\\pm$ 0.81 & 8.8h $\\pm$ 2.2h & 1.0x & 200.0 $\\pm$ 0.0\n",
      "PASHA VACC-AUTO & 45.13 $\\pm$ 1.51 & 2.9h $\\pm$ 1.7h & 3.1x & 21.3 $\\pm$ 48.1\n",
      "One epoch baseline VACC  & 41.42 $\\pm$ 4.98 & 1.0h $\\pm$ 0.0h & 8.8x & 1.0 $\\pm$ 0.0\n",
      "Random baseline  & 20.97 $\\pm$ 10.01 & 0.0h $\\pm$ 0.0h & NA & 0.0 $\\pm$ 0.0\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in dataset_names:\n",
    "    print(dataset_name)\n",
    "    result_summary, reference_time = analyse_experiments(experiment_names_asha_val_acc)\n",
    "    print('ASHA VACC' + result_summary)\n",
    "    result_summary, _ = analyse_experiments(experiment_names_pasha_val_acc_auto, reference_time)\n",
    "    print('PASHA VACC-AUTO' + result_summary)\n",
    "    result_summary = compute_one_epoch_baseline()\n",
    "    print('One epoch baseline VACC', result_summary)\n",
    "    result_summary = compute_random_baseline()\n",
    "    print('Random baseline', result_summary)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7301c6f-4a61-4807-b2c0-ff6d8cffc9db",
   "metadata": {},
   "source": [
    "Next we do experiments with different pruning ratios - 2 and 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8aa178c0-ec83-4368-9d78-cf5e1896c5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "experiment_names_asha_vacc_2 = {dataset: [] for dataset in dataset_names}\n",
    "experiment_names_pasha_vacc_auto_2 = {dataset: [] for dataset in dataset_names}\n",
    "experiment_names_asha_vacc_4 = {dataset: [] for dataset in dataset_names}\n",
    "experiment_names_pasha_vacc_auto_4 = {dataset: [] for dataset in dataset_names}\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    for nb201_random_seed in nb201_random_seeds:\n",
    "        for random_seed in random_seeds:\n",
    "            experiment_name = run_experiment(dataset_name, random_seed, nb201_random_seed, 'asha', benchmark_metric='metric_valid_error', reduction_factor=2)\n",
    "            experiment_names_asha_vacc_2[dataset_name].append((experiment_name, nb201_random_seed))\n",
    "            experiment_name = run_experiment(dataset_name, random_seed, nb201_random_seed, 'pasha', benchmark_metric='metric_valid_error', rung_system_kwargs={'ranking_criterion': 'soft_ranking_auto', 'epsilon': 0.0}, reduction_factor=2)\n",
    "            experiment_names_pasha_vacc_auto_2[dataset_name].append((experiment_name, nb201_random_seed))\n",
    "            experiment_name = run_experiment(dataset_name, random_seed, nb201_random_seed, 'asha', benchmark_metric='metric_valid_error', reduction_factor=4)\n",
    "            experiment_names_asha_vacc_4[dataset_name].append((experiment_name, nb201_random_seed))\n",
    "            experiment_name = run_experiment(dataset_name, random_seed, nb201_random_seed, 'pasha', benchmark_metric='metric_valid_error', rung_system_kwargs={'ranking_criterion': 'soft_ranking_auto', 'epsilon': 0.0}, reduction_factor=4)\n",
    "            experiment_names_pasha_vacc_auto_4[dataset_name].append((experiment_name, nb201_random_seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daac2cd0-decc-4701-8fa5-38a58c464e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource level 2\n",
      "cifar10\n",
      "ASHA VACC & 93.88 $\\pm$ 0.27 & 3.6h $\\pm$ 1.1h & 1.0x & 200.0 $\\pm$ 0.0\n",
      "PASHA VACC-AUTO & 93.53 $\\pm$ 0.76 & 1.0h $\\pm$ 0.3h & 3.5x & 9.1 $\\pm$ 8.1\n",
      "cifar100\n",
      "ASHA VACC & 71.67 $\\pm$ 0.84 & 3.8h $\\pm$ 1.0h & 1.0x & 200.0 $\\pm$ 0.0\n",
      "PASHA VACC-AUTO & 71.65 $\\pm$ 1.42 & 0.9h $\\pm$ 0.1h & 4.2x & 5.9 $\\pm$ 2.0\n",
      "ImageNet16-120\n",
      "ASHA VACC & 46.09 $\\pm$ 0.68 & 11.9h $\\pm$ 4.0h & 1.0x & 200.0 $\\pm$ 0.0\n",
      "PASHA VACC-AUTO & 45.35 $\\pm$ 1.52 & 2.8h $\\pm$ 0.6h & 4.2x & 9.3 $\\pm$ 7.1\n",
      "Resource level 4\n",
      "cifar10\n",
      "ASHA VACC & 93.75 $\\pm$ 0.28 & 2.4h $\\pm$ 0.6h & 1.0x & 200.0 $\\pm$ 0.0\n",
      "PASHA VACC-AUTO & 93.65 $\\pm$ 0.65 & 1.1h $\\pm$ 0.5h & 2.3x & 32.3 $\\pm$ 50.2\n",
      "cifar100\n",
      "ASHA VACC & 71.43 $\\pm$ 1.13 & 2.7h $\\pm$ 0.9h & 1.0x & 200.0 $\\pm$ 0.0\n",
      "PASHA VACC-AUTO & 72.09 $\\pm$ 1.22 & 1.0h $\\pm$ 0.4h & 2.8x & 25.1 $\\pm$ 49.0\n",
      "ImageNet16-120\n",
      "ASHA VACC & 45.43 $\\pm$ 0.98 & 7.9h $\\pm$ 3.0h & 1.0x & 200.0 $\\pm$ 0.0\n",
      "PASHA VACC-AUTO & 45.52 $\\pm$ 1.30 & 2.9h $\\pm$ 1.1h & 2.8x & 18.4 $\\pm$ 18.7\n"
     ]
    }
   ],
   "source": [
    "print('Resource level 2')\n",
    "for dataset_name in dataset_names:\n",
    "    print(dataset_name)\n",
    "    result_summary, reference_time = analyse_experiments(experiment_names_asha_vacc_2)\n",
    "    print('ASHA VACC' + result_summary)\n",
    "    result_summary, _ = analyse_experiments(experiment_names_pasha_vacc_auto_2, reference_time)\n",
    "    print('PASHA VACC-AUTO' + result_summary)\n",
    "\n",
    "print('Resource level 4')\n",
    "for dataset_name in dataset_names:\n",
    "    print(dataset_name)\n",
    "    result_summary, reference_time = analyse_experiments(experiment_names_asha_vacc_4)\n",
    "    print('ASHA VACC' + result_summary)\n",
    "    result_summary, _ = analyse_experiments(experiment_names_pasha_vacc_auto_4, reference_time)\n",
    "    print('PASHA VACC-AUTO' + result_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b135bad2-26d2-430e-8332-610a945e5b0e",
   "metadata": {},
   "source": [
    "Analysis of the BO experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab3a54da-f3f7-43e1-a69d-b447bca37ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to load the names of the configurations from the json file where we store it\n",
    "with open('bo_experiment_details_auto_vacc.json', 'r') as f:\n",
    "    bo_experiment_details = json.load(f)\n",
    "\n",
    "experiment_names_pasha_bo = {dataset: [] for dataset in dataset_names}\n",
    "experiment_names_asha_bo = {dataset: [] for dataset in dataset_names}\n",
    "\n",
    "# load the details of the experiments\n",
    "for detail_dict in bo_experiment_details:\n",
    "    if detail_dict['scheduler'] == 'asha-bo':\n",
    "        experiment_names_asha_bo[detail_dict['dataset_name']].append((detail_dict['experiment_name'], detail_dict['nb201_random_seed']))\n",
    "    elif detail_dict['scheduler'] == 'pasha-bo':\n",
    "        experiment_names_pasha_bo[detail_dict['dataset_name']].append((detail_dict['experiment_name'], detail_dict['nb201_random_seed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6cafed8-f751-4f8a-9d76-cef2b296956a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar10\n",
      "ASHA & 94.21 $\\pm$ 0.28 & 5.0h $\\pm$ 1.1h & 1.0x & 200.0 $\\pm$ 0.0\n",
      "PASHA & 94.00 $\\pm$ 0.20 & 2.6h $\\pm$ 1.8h & 2.0x & 70.7 $\\pm$ 81.6\n",
      "cifar100\n",
      "ASHA & 72.79 $\\pm$ 0.68 & 5.7h $\\pm$ 1.4h & 1.0x & 200.0 $\\pm$ 0.0\n",
      "PASHA & 72.16 $\\pm$ 1.07 & 1.6h $\\pm$ 0.5h & 3.7x & 13.0 $\\pm$ 8.7\n",
      "ImageNet16-120\n",
      "ASHA & 46.21 $\\pm$ 0.70 & 15.1h $\\pm$ 4.0h & 1.0x & 200.0 $\\pm$ 0.0\n",
      "PASHA & 45.36 $\\pm$ 1.06 & 3.9h $\\pm$ 1.2h & 3.9x & 11.8 $\\pm$ 7.9\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in dataset_names:\n",
    "    print(dataset_name)\n",
    "    result_summary, reference_time = analyse_experiments(experiment_names_asha_bo)\n",
    "    print('ASHA' + result_summary)\n",
    "    result_summary, _ = analyse_experiments(experiment_names_pasha_bo, reference_time)\n",
    "    print('PASHA' + result_summary)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fd3581-74f9-458f-8387-43215e52b043",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PD1 experiments and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e4c282a-ca54-4619-a5ab-2d4db5286c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syne_tune.blackbox_repository.conversion_scripts.scripts.pd1_import import (\n",
    "    BLACKBOX_NAME, COLUMN_RENAMING, CONFIGURATION_SPACE, METRIC_ELAPSED_TIME,\n",
    "    METRIC_VALID_ERROR, RESOURCE_ATTR)\n",
    "\n",
    "from syne_tune.blackbox_repository import add_surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6115521e-4bb4-432a-8366-6f8669902bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_dict = load_blackbox('pd1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45247fe7-1a82-418c-88a9-73a1aef480ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_valid_error_dim = 0\n",
    "metric_runtime_dim = 2\n",
    "dataset_names = ['imagenet_resnet_batch_size_512', 'translate_wmt_xformer_translate_batch_size_64']\n",
    "random_seeds = [31415927, 0, 1234, 3458, 7685]\n",
    "n_workers = 4\n",
    "\n",
    "df_dict = {0: {}}\n",
    "seed = 0\n",
    "\n",
    "for dataset in dataset_names:\n",
    "    num_epochs = bb_dict[dataset].objectives_evaluations.shape[2]\n",
    "    epoch_names = ['val_acc_epoch_' + str(e) for e in range(num_epochs)]\n",
    "    # create a dataframe with the validation accuracies for various epochs\n",
    "    df_val_acc = pd.DataFrame((1.0-bb_dict[dataset].objectives_evaluations[:, seed, :, metric_valid_error_dim]) * 100, columns=['val_acc_epoch_' + str(e) for e in range(num_epochs)])\n",
    "    \n",
    "    # add a new column with the best validation accuracy\n",
    "    df_val_acc['val_acc_best'] = df_val_acc[epoch_names].max(axis=1)\n",
    "    # create a dataframe with the hyperparameter values\n",
    "    df_hp = bb_dict[dataset].hyperparameters\n",
    "    # create a dataframe with the times it takes to run an epoch\n",
    "    df_time = pd.DataFrame(bb_dict[dataset].objectives_evaluations[:, seed, :, metric_runtime_dim][:, -1]/bb_dict[dataset].objectives_evaluations.shape[2], columns=['eval_time_epoch'])    \n",
    "    # combine all smaller dataframes into one dataframe for each random seed and dataset\n",
    "    df_dict[seed][dataset] = pd.concat([df_hp, df_val_acc, df_time], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88fab849-9942-46ee-919c-584de6784fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_initial_value</th>\n",
       "      <th>lr_power</th>\n",
       "      <th>lr_decay_steps_factor</th>\n",
       "      <th>one_minus_momentum</th>\n",
       "      <th>val_acc_epoch_0</th>\n",
       "      <th>val_acc_epoch_1</th>\n",
       "      <th>val_acc_epoch_2</th>\n",
       "      <th>val_acc_epoch_3</th>\n",
       "      <th>val_acc_epoch_4</th>\n",
       "      <th>val_acc_epoch_5</th>\n",
       "      <th>...</th>\n",
       "      <th>val_acc_epoch_243</th>\n",
       "      <th>val_acc_epoch_244</th>\n",
       "      <th>val_acc_epoch_245</th>\n",
       "      <th>val_acc_epoch_246</th>\n",
       "      <th>val_acc_epoch_247</th>\n",
       "      <th>val_acc_epoch_248</th>\n",
       "      <th>val_acc_epoch_249</th>\n",
       "      <th>val_acc_epoch_250</th>\n",
       "      <th>val_acc_best</th>\n",
       "      <th>eval_time_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000333</td>\n",
       "      <td>1.154020</td>\n",
       "      <td>0.234034</td>\n",
       "      <td>0.975224</td>\n",
       "      <td>1.286024</td>\n",
       "      <td>2.010041</td>\n",
       "      <td>2.224046</td>\n",
       "      <td>2.524048</td>\n",
       "      <td>2.786058</td>\n",
       "      <td>2.970058</td>\n",
       "      <td>...</td>\n",
       "      <td>8.250165</td>\n",
       "      <td>8.234167</td>\n",
       "      <td>8.312166</td>\n",
       "      <td>8.252168</td>\n",
       "      <td>8.240164</td>\n",
       "      <td>8.238167</td>\n",
       "      <td>8.264166</td>\n",
       "      <td>8.262163</td>\n",
       "      <td>8.312166</td>\n",
       "      <td>26.908581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.572230</td>\n",
       "      <td>0.455548</td>\n",
       "      <td>0.905727</td>\n",
       "      <td>0.490010</td>\n",
       "      <td>0.830019</td>\n",
       "      <td>1.052022</td>\n",
       "      <td>1.258028</td>\n",
       "      <td>1.420027</td>\n",
       "      <td>1.628035</td>\n",
       "      <td>...</td>\n",
       "      <td>5.924118</td>\n",
       "      <td>5.934119</td>\n",
       "      <td>5.912119</td>\n",
       "      <td>5.930120</td>\n",
       "      <td>5.928117</td>\n",
       "      <td>5.912119</td>\n",
       "      <td>5.904120</td>\n",
       "      <td>5.928117</td>\n",
       "      <td>5.946117</td>\n",
       "      <td>29.569784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.175994</td>\n",
       "      <td>0.681017</td>\n",
       "      <td>0.568908</td>\n",
       "      <td>0.134003</td>\n",
       "      <td>0.184005</td>\n",
       "      <td>0.316006</td>\n",
       "      <td>0.398010</td>\n",
       "      <td>0.512010</td>\n",
       "      <td>0.566012</td>\n",
       "      <td>...</td>\n",
       "      <td>3.484070</td>\n",
       "      <td>3.440070</td>\n",
       "      <td>3.478068</td>\n",
       "      <td>3.488070</td>\n",
       "      <td>3.476071</td>\n",
       "      <td>3.462070</td>\n",
       "      <td>3.440070</td>\n",
       "      <td>3.460068</td>\n",
       "      <td>3.504068</td>\n",
       "      <td>25.339344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000018</td>\n",
       "      <td>1.770602</td>\n",
       "      <td>0.431815</td>\n",
       "      <td>0.492782</td>\n",
       "      <td>0.130004</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.128001</td>\n",
       "      <td>0.124002</td>\n",
       "      <td>0.126004</td>\n",
       "      <td>0.124002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296009</td>\n",
       "      <td>0.296009</td>\n",
       "      <td>0.296009</td>\n",
       "      <td>0.296009</td>\n",
       "      <td>0.294006</td>\n",
       "      <td>0.298005</td>\n",
       "      <td>0.296009</td>\n",
       "      <td>0.300008</td>\n",
       "      <td>0.302005</td>\n",
       "      <td>31.448215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000503</td>\n",
       "      <td>1.103766</td>\n",
       "      <td>0.943076</td>\n",
       "      <td>0.997958</td>\n",
       "      <td>2.498049</td>\n",
       "      <td>4.536092</td>\n",
       "      <td>6.342125</td>\n",
       "      <td>8.362168</td>\n",
       "      <td>10.474211</td>\n",
       "      <td>12.362247</td>\n",
       "      <td>...</td>\n",
       "      <td>74.217484</td>\n",
       "      <td>74.211487</td>\n",
       "      <td>74.199486</td>\n",
       "      <td>74.177483</td>\n",
       "      <td>74.161484</td>\n",
       "      <td>74.143478</td>\n",
       "      <td>74.209488</td>\n",
       "      <td>74.145485</td>\n",
       "      <td>74.217484</td>\n",
       "      <td>29.043724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>0.217098</td>\n",
       "      <td>1.562599</td>\n",
       "      <td>0.772744</td>\n",
       "      <td>0.903084</td>\n",
       "      <td>8.954180</td>\n",
       "      <td>17.652351</td>\n",
       "      <td>22.806454</td>\n",
       "      <td>30.388605</td>\n",
       "      <td>34.288685</td>\n",
       "      <td>34.964699</td>\n",
       "      <td>...</td>\n",
       "      <td>76.943542</td>\n",
       "      <td>77.073540</td>\n",
       "      <td>77.005539</td>\n",
       "      <td>77.041542</td>\n",
       "      <td>77.031540</td>\n",
       "      <td>77.025536</td>\n",
       "      <td>77.021538</td>\n",
       "      <td>77.021538</td>\n",
       "      <td>77.073540</td>\n",
       "      <td>44.679020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>5.645541</td>\n",
       "      <td>0.773464</td>\n",
       "      <td>0.018352</td>\n",
       "      <td>0.958217</td>\n",
       "      <td>0.842017</td>\n",
       "      <td>2.046043</td>\n",
       "      <td>5.194104</td>\n",
       "      <td>10.298204</td>\n",
       "      <td>24.756496</td>\n",
       "      <td>25.840515</td>\n",
       "      <td>...</td>\n",
       "      <td>68.311371</td>\n",
       "      <td>68.521370</td>\n",
       "      <td>68.397369</td>\n",
       "      <td>68.279358</td>\n",
       "      <td>68.117363</td>\n",
       "      <td>68.487373</td>\n",
       "      <td>68.659378</td>\n",
       "      <td>68.233368</td>\n",
       "      <td>68.659378</td>\n",
       "      <td>44.041317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>1.208451</td>\n",
       "      <td>1.753618</td>\n",
       "      <td>0.819584</td>\n",
       "      <td>0.998627</td>\n",
       "      <td>0.104004</td>\n",
       "      <td>0.988019</td>\n",
       "      <td>0.566012</td>\n",
       "      <td>0.846016</td>\n",
       "      <td>0.758016</td>\n",
       "      <td>0.704014</td>\n",
       "      <td>...</td>\n",
       "      <td>29.752594</td>\n",
       "      <td>29.802597</td>\n",
       "      <td>30.206602</td>\n",
       "      <td>29.858595</td>\n",
       "      <td>30.326605</td>\n",
       "      <td>30.574614</td>\n",
       "      <td>30.328608</td>\n",
       "      <td>30.998617</td>\n",
       "      <td>30.998617</td>\n",
       "      <td>52.782589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>0.382426</td>\n",
       "      <td>1.843956</td>\n",
       "      <td>0.267077</td>\n",
       "      <td>0.216799</td>\n",
       "      <td>4.538089</td>\n",
       "      <td>8.152163</td>\n",
       "      <td>10.762215</td>\n",
       "      <td>14.936298</td>\n",
       "      <td>17.936361</td>\n",
       "      <td>19.718397</td>\n",
       "      <td>...</td>\n",
       "      <td>67.847359</td>\n",
       "      <td>67.841354</td>\n",
       "      <td>67.791351</td>\n",
       "      <td>67.807350</td>\n",
       "      <td>67.775360</td>\n",
       "      <td>67.813362</td>\n",
       "      <td>67.777359</td>\n",
       "      <td>67.775360</td>\n",
       "      <td>67.847359</td>\n",
       "      <td>45.980042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.771857</td>\n",
       "      <td>0.118723</td>\n",
       "      <td>0.954479</td>\n",
       "      <td>0.140005</td>\n",
       "      <td>0.208002</td>\n",
       "      <td>0.322008</td>\n",
       "      <td>0.402009</td>\n",
       "      <td>0.460011</td>\n",
       "      <td>0.568008</td>\n",
       "      <td>...</td>\n",
       "      <td>1.264024</td>\n",
       "      <td>1.256025</td>\n",
       "      <td>1.270026</td>\n",
       "      <td>1.262027</td>\n",
       "      <td>1.268023</td>\n",
       "      <td>1.256025</td>\n",
       "      <td>1.270026</td>\n",
       "      <td>1.254022</td>\n",
       "      <td>1.274025</td>\n",
       "      <td>44.754227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2081 rows Ã— 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lr_initial_value  lr_power  lr_decay_steps_factor  one_minus_momentum  \\\n",
       "0             0.000333  1.154020               0.234034            0.975224   \n",
       "1             0.000293  0.572230               0.455548            0.905727   \n",
       "2             0.000285  0.175994               0.681017            0.568908   \n",
       "3             0.000018  1.770602               0.431815            0.492782   \n",
       "4             0.000503  1.103766               0.943076            0.997958   \n",
       "...                ...       ...                    ...                 ...   \n",
       "2076          0.217098  1.562599               0.772744            0.903084   \n",
       "2077          5.645541  0.773464               0.018352            0.958217   \n",
       "2078          1.208451  1.753618               0.819584            0.998627   \n",
       "2079          0.382426  1.843956               0.267077            0.216799   \n",
       "2080          0.000032  0.771857               0.118723            0.954479   \n",
       "\n",
       "      val_acc_epoch_0  val_acc_epoch_1  val_acc_epoch_2  val_acc_epoch_3  \\\n",
       "0            1.286024         2.010041         2.224046         2.524048   \n",
       "1            0.490010         0.830019         1.052022         1.258028   \n",
       "2            0.134003         0.184005         0.316006         0.398010   \n",
       "3            0.130004         0.132000         0.128001         0.124002   \n",
       "4            2.498049         4.536092         6.342125         8.362168   \n",
       "...               ...              ...              ...              ...   \n",
       "2076         8.954180        17.652351        22.806454        30.388605   \n",
       "2077         0.842017         2.046043         5.194104        10.298204   \n",
       "2078         0.104004         0.988019         0.566012         0.846016   \n",
       "2079         4.538089         8.152163        10.762215        14.936298   \n",
       "2080         0.140005         0.208002         0.322008         0.402009   \n",
       "\n",
       "      val_acc_epoch_4  val_acc_epoch_5  ...  val_acc_epoch_243  \\\n",
       "0            2.786058         2.970058  ...           8.250165   \n",
       "1            1.420027         1.628035  ...           5.924118   \n",
       "2            0.512010         0.566012  ...           3.484070   \n",
       "3            0.126004         0.124002  ...           0.296009   \n",
       "4           10.474211        12.362247  ...          74.217484   \n",
       "...               ...              ...  ...                ...   \n",
       "2076        34.288685        34.964699  ...          76.943542   \n",
       "2077        24.756496        25.840515  ...          68.311371   \n",
       "2078         0.758016         0.704014  ...          29.752594   \n",
       "2079        17.936361        19.718397  ...          67.847359   \n",
       "2080         0.460011         0.568008  ...           1.264024   \n",
       "\n",
       "      val_acc_epoch_244  val_acc_epoch_245  val_acc_epoch_246  \\\n",
       "0              8.234167           8.312166           8.252168   \n",
       "1              5.934119           5.912119           5.930120   \n",
       "2              3.440070           3.478068           3.488070   \n",
       "3              0.296009           0.296009           0.296009   \n",
       "4             74.211487          74.199486          74.177483   \n",
       "...                 ...                ...                ...   \n",
       "2076          77.073540          77.005539          77.041542   \n",
       "2077          68.521370          68.397369          68.279358   \n",
       "2078          29.802597          30.206602          29.858595   \n",
       "2079          67.841354          67.791351          67.807350   \n",
       "2080           1.256025           1.270026           1.262027   \n",
       "\n",
       "      val_acc_epoch_247  val_acc_epoch_248  val_acc_epoch_249  \\\n",
       "0              8.240164           8.238167           8.264166   \n",
       "1              5.928117           5.912119           5.904120   \n",
       "2              3.476071           3.462070           3.440070   \n",
       "3              0.294006           0.298005           0.296009   \n",
       "4             74.161484          74.143478          74.209488   \n",
       "...                 ...                ...                ...   \n",
       "2076          77.031540          77.025536          77.021538   \n",
       "2077          68.117363          68.487373          68.659378   \n",
       "2078          30.326605          30.574614          30.328608   \n",
       "2079          67.775360          67.813362          67.777359   \n",
       "2080           1.268023           1.256025           1.270026   \n",
       "\n",
       "      val_acc_epoch_250  val_acc_best  eval_time_epoch  \n",
       "0              8.262163      8.312166        26.908581  \n",
       "1              5.928117      5.946117        29.569784  \n",
       "2              3.460068      3.504068        25.339344  \n",
       "3              0.300008      0.302005        31.448215  \n",
       "4             74.145485     74.217484        29.043724  \n",
       "...                 ...           ...              ...  \n",
       "2076          77.021538     77.073540        44.679020  \n",
       "2077          68.233368     68.659378        44.041317  \n",
       "2078          30.998617     30.998617        52.782589  \n",
       "2079          67.775360     67.847359        45.980042  \n",
       "2080           1.254022      1.274025        44.754227  \n",
       "\n",
       "[2081 rows x 257 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict[0]['imagenet_resnet_batch_size_512']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49472dab-66b6-4adb-8f28-7517b876385e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(121)\n",
    "plt.hist(df_dict[0]['imagenet_resnet_batch_size_512']['val_acc_best'], bins=100)\n",
    "plt.xlabel('Best validation accuracy (%)', fontsize=14)\n",
    "plt.title('imagenet_resnet_batch_size_512', fontsize=16)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(df_dict[0]['translate_wmt_xformer_translate_batch_size_64']['val_acc_best'], bins=100)\n",
    "plt.xlabel('Best validation accuracy (%)', fontsize=14)\n",
    "plt.title('translate_wmt_xformer_translate_batch_size_64', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e7912f-f4c5-4454-9323-a1dcbabbf141",
   "metadata": {},
   "source": [
    "This looks good so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "005141d0-6c63-4144-8557-1ad035c191bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_pd1(dataset_name, random_seed, benchmark_random_seed, hpo_approach, reduction_factor=None, rung_system_kwargs={'ranking_criterion': 'soft_ranking', 'epsilon': 0.025}, benchmark_metric='metric_valid_error', benchmark='nasbench201', benchmark_mode=None):\n",
    "    \"\"\"\n",
    "    Function to run an experiment. It is similar to the NASBench201 example script\n",
    "    in syne-tune but extended to make it simple to run our experiments.\n",
    "    \n",
    "    When describing the following parameters we say what values we use, but feel free to also use other values.\n",
    "    \n",
    "    :param dataset_name: one of 'imagenet_resnet_batch_size_512', 'translate_wmt_xformer_translate_batch_size_64'\n",
    "    :param random_seed: one of 31415927, 0, 1234, 3458, 7685\n",
    "    :param benchmark_random_seed: 0\n",
    "    :param hpo_approach: one of 'pasha', 'asha', 'pasha-bo', 'asha-bo'\n",
    "    :param reduction_factor: by default None (resulting in using the default value 3) or 2, 4\n",
    "    :param rung_system_kwargs: dictionary of ranking criterion (str) and epsilon or epsilon scaling (both float)\n",
    "    :return: tuner.name\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # this function is similar to the NASBench201 example script\n",
    "    logging.getLogger().setLevel(logging.WARNING)\n",
    "    \n",
    "    n_workers = 4\n",
    "    resource_attr = RESOURCE_ATTR\n",
    "    blackbox_name = BLACKBOX_NAME\n",
    "    elapsed_time_attr = METRIC_ELAPSED_TIME\n",
    "    surrogate = \"KNeighborsRegressor\"\n",
    "    surrogate_kwargs = {\"n_neighbors\": 1}\n",
    "\n",
    "    metric = benchmark_metric  # benchmark['metric']\n",
    "\n",
    "    config_space = CONFIGURATION_SPACE\n",
    "    config_space['dataset_name'] = dataset_name\n",
    "\n",
    "    max_t_dict = {'imagenet_resnet_batch_size_512': 251,\n",
    "                  'translate_wmt_xformer_translate_batch_size_64': 1414}\n",
    "\n",
    "    max_t = max_t_dict[dataset_name]\n",
    "    grace_period = 1\n",
    "    \n",
    "    if benchmark_mode:\n",
    "        mode = benchmark_mode\n",
    "    else:\n",
    "        mode = 'min'\n",
    "\n",
    "    # simulator back-end specialized to tabulated blackboxes\n",
    "    trial_backend = BlackboxRepositoryBackend(\n",
    "        blackbox_name=blackbox_name,\n",
    "        elapsed_time_attr=elapsed_time_attr,\n",
    "        dataset=dataset_name,\n",
    "        seed=benchmark_random_seed,\n",
    "        surrogate=surrogate, surrogate_kwargs=surrogate_kwargs)\n",
    "\n",
    "    # set logging of the simulator backend to WARNING level\n",
    "    logging.getLogger('syne_tune.backend.simulator_backend.simulator_backend').setLevel(logging.WARNING)\n",
    "    \n",
    "    if not reduction_factor:\n",
    "        reduction_factor = 3\n",
    "            \n",
    "    # we support various schedulers within the function\n",
    "    # NOTE: previously we used resource_attr instead of max_resource_attr\n",
    "    if hpo_approach == 'pasha':\n",
    "        scheduler = baselines_dict['PASHA'](\n",
    "            config_space,\n",
    "            max_t=max_t,\n",
    "            grace_period=grace_period,\n",
    "            reduction_factor=reduction_factor,\n",
    "            resource_attr=resource_attr,\n",
    "            mode=mode,\n",
    "            metric=metric,\n",
    "            random_seed=random_seed,\n",
    "            rung_system_kwargs=rung_system_kwargs)\n",
    "    elif hpo_approach == 'asha':\n",
    "        scheduler = baselines_dict['ASHA'](\n",
    "            config_space,\n",
    "            max_t=max_t,\n",
    "            grace_period=grace_period,\n",
    "            reduction_factor=reduction_factor,\n",
    "            resource_attr=resource_attr,\n",
    "            mode=mode,\n",
    "            type='promotion',\n",
    "            metric=metric,\n",
    "            random_seed=random_seed)\n",
    "    elif hpo_approach == 'pasha-bo':\n",
    "        scheduler = HyperbandScheduler(\n",
    "            config_space,\n",
    "            max_t=max_t,\n",
    "            grace_period=grace_period,\n",
    "            reduction_factor=reduction_factor,\n",
    "            resource_attr=resource_attr,\n",
    "            mode=mode,\n",
    "            searcher='bayesopt',\n",
    "            type='pasha',\n",
    "            metric=metric,\n",
    "            random_seed=random_seed,\n",
    "            rung_system_kwargs=rung_system_kwargs)\n",
    "    elif hpo_approach == 'asha-bo':\n",
    "        scheduler = HyperbandScheduler(\n",
    "            config_space,\n",
    "            max_t=max_t,\n",
    "            grace_period=grace_period,\n",
    "            reduction_factor=reduction_factor,\n",
    "            resource_attr=resource_attr,\n",
    "            mode=mode,\n",
    "            searcher='bayesopt',\n",
    "            type='promotion',\n",
    "            metric=metric,\n",
    "            random_seed=random_seed)\n",
    "    else:\n",
    "        raise ValueError('The selected scheduler is not implemented')\n",
    "\n",
    "    stop_criterion = StoppingCriterion(max_num_trials_started=256)\n",
    "\n",
    "    tuner = Tuner(\n",
    "        trial_backend=trial_backend,\n",
    "        scheduler=scheduler,\n",
    "        stop_criterion=stop_criterion,\n",
    "        n_workers=n_workers,\n",
    "        sleep_time=0,\n",
    "        callbacks=[SimulatorCallback()],\n",
    "    )\n",
    "    \n",
    "    tuner.run()\n",
    "    \n",
    "    return tuner.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7858a2e8-1deb-4685-af0e-50213816753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_experiments_pd1(experiment_names_dict, reference_time=None):\n",
    "    \"\"\"\n",
    "    Function to analyse the experiments that we run with run_experiment function.\n",
    "    \n",
    "    :param experiment_names_dict: dictionary mapping the dataset names to tuples of\n",
    "        experiment names and NASBench201 random seeds\n",
    "    :reference_time: optional argument with the time it takes to run the standard method - e.g. ASHA\n",
    "    :return: tuple of a line to display (string reporting the experiment results) and \n",
    "        the mean of the runtimes that can be used as reference time for other approaches\n",
    "    \"\"\"\n",
    "    val_acc_best_list = []\n",
    "    max_rsc_list = []\n",
    "    runtime_list = []\n",
    "    bbs = add_surrogate(bb_dict[dataset_name], surrogate=None)\n",
    "    \n",
    "    for experiment_name, nb201_random_seed in experiment_names_dict[dataset_name]:\n",
    "        experiment_results = load_experiment(experiment_name)\n",
    "        best_cfg = experiment_results.results['metric_valid_error_rate'].argmin()\n",
    "\n",
    "        # find the test accuracy of the corresponding entry\n",
    "        table_hp_names = ['lr_initial_value', 'lr_power', 'lr_decay_steps_factor', 'one_minus_momentum']\n",
    "        results_hp_names = ['config_' + str(hp_name) for hp_name in table_hp_names]\n",
    "        best_cfg_hps = experiment_results.results[results_hp_names].iloc[best_cfg].tolist()\n",
    "        best_cfg_hps_dict = {k:v for k, v in zip(table_hp_names, best_cfg_hps)} \n",
    "        \n",
    "        val_acc_best = bbs.objective_function(best_cfg_hps_dict)[:, metric_valid_error_dim].min()\n",
    "        val_acc_best_list.append((1.0 - val_acc_best) * 100.0)\n",
    "        \n",
    "        max_rsc_list.append(experiment_results.results['global_step'].max())\n",
    "        runtime_list.append(experiment_results.results['st_tuner_time'].max())\n",
    "        \n",
    "    line = ' & {:.2f} $\\pm$ {:.2f}'.format(np.mean(val_acc_best_list), np.std(val_acc_best_list))\n",
    "    line += ' & {:.1f}h $\\pm$ {:.1f}h'.format(np.mean(runtime_list)/3600, np.std(runtime_list)/3600)\n",
    "    if reference_time:\n",
    "        line += ' & {:.1f}x'.format(reference_time/np.mean(runtime_list))\n",
    "    else:\n",
    "        line += ' & {:.1f}x'.format(np.mean(runtime_list)/np.mean(runtime_list))\n",
    "    line += ' & {:.1f} $\\pm$ {:.1f}'.format(np.mean(max_rsc_list), np.std(max_rsc_list))\n",
    "    \n",
    "    return line, np.mean(runtime_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b547b2cc-fc4e-4110-9d58-ff63b230700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_one_epoch_baseline_pd1(dataset_name, metric='val_err'):\n",
    "    \"\"\"\n",
    "    Function to compute the performance of a simple one epoch baseline.\n",
    "    :return: a line to display (string reporting the experiment results)\n",
    "    \"\"\"  \n",
    "    val_acc_best_list = []\n",
    "    total_time_list = []\n",
    "        \n",
    "    bbs = add_surrogate(bb_dict[dataset_name], surrogate=None)\n",
    "\n",
    "    for random_seed in random_seeds:\n",
    "        random.seed(random_seed)\n",
    "        random_seeds_rb = random.sample(range(999999), 256)\n",
    "        time_sum = 0.0\n",
    "\n",
    "        if metric == 'val_err':\n",
    "            metric_score_dim = metric_valid_error_dim\n",
    "            benchmark_mode = 'min'\n",
    "            best_metric_score = 10000.0\n",
    "            best_hps = None\n",
    "        else:\n",
    "            raise ValueError('Metric ' + metric + ' currently not supported')\n",
    "\n",
    "        for random_seed_rb in random_seeds_rb:\n",
    "            np.random.seed(random_seed_rb)\n",
    "            sampled_hps = {k: v.sample() for k, v in bb_dict[dataset_name].configuration_space.items()}\n",
    "            metric_score = bbs.objective_function(sampled_hps)[0, metric_score_dim]\n",
    "            time_sum += bbs.objective_function(sampled_hps)[0, metric_runtime_dim]\n",
    "\n",
    "            if benchmark_mode == 'min':\n",
    "                if metric_score < best_metric_score:\n",
    "                    best_metric_score = metric_score\n",
    "                    best_hps = sampled_hps\n",
    "            else:\n",
    "                if metric_score > best_metric_score:\n",
    "                    best_metric_score = metric_score\n",
    "                    best_hps = sampled_hps\n",
    "\n",
    "        # now we have found the best configuration\n",
    "        # the dataframe contains validation error rates\n",
    "        val_acc_best = bbs.objective_function(best_hps)[:, metric_score_dim].min()\n",
    "        val_acc_best_list.append((1.0 - val_acc_best) * 100.0)\n",
    "\n",
    "        # we also need to calculate the time it took for this\n",
    "        # taking into account the number of workers\n",
    "        total_time = time_sum / n_workers\n",
    "        total_time_list.append(total_time)\n",
    "\n",
    "    line = ' & {:.2f} $\\pm$ {:.2f}'.format(np.mean(val_acc_best_list), np.std(val_acc_best_list))\n",
    "    line += ' & {:.1f}h $\\pm$ {:.1f}h'.format(np.mean(total_time_list)/3600, np.std(total_time_list)/3600)\n",
    "    line += ' & {:.1f}x'.format(reference_time/np.mean(total_time_list))\n",
    "    line += ' & 1.0 $\\pm$ 0.0'\n",
    "\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "742847dd-dc03-439c-b2d7-0fd42544ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_random_baseline_pd1(dataset_name):\n",
    "    \"\"\"\n",
    "    Function to compute the performance of a simple random configuration baseline.\n",
    "    \n",
    "    We consider a ten times larger number of configurations in this case to get a better\n",
    "    estimate of the performance of a random configuration.\n",
    "\n",
    "    :return: a line to display (string reporting the experiment results)\n",
    "    \"\"\"\n",
    "    val_acc_best_list = []\n",
    "    total_time_list = []\n",
    "    metric_score_dim = metric_valid_error_dim\n",
    "\n",
    "    random.seed(0)\n",
    "    random_seeds_rb = random.sample(range(999999), 256 * 10)\n",
    "\n",
    "    bbs = add_surrogate(bb_dict[dataset_name], surrogate=None)\n",
    "\n",
    "    for random_seed in random_seeds_rb:\n",
    "        np.random.seed(random_seed)\n",
    "        sampled_hps = {k: v.sample() for k, v in bb_dict[dataset_name].configuration_space.items()}\n",
    "        val_acc_best = bbs.objective_function(sampled_hps)[:, metric_score_dim].min()\n",
    "        val_acc_best_list.append((1.0 - val_acc_best) * 100.0)\n",
    "\n",
    "        # we also need to calculate the time it took for this\n",
    "        total_time = 0.0\n",
    "        total_time_list.append(total_time)\n",
    "\n",
    "    line = ' & {:.2f} $\\pm$ {:.2f}'.format(np.mean(val_acc_best_list), np.std(val_acc_best_list))\n",
    "    line += ' & {:.1f}h $\\pm$ {:.1f}h'.format(np.mean(total_time_list)/3600, np.std(total_time_list)/3600)\n",
    "    line += ' & NA'\n",
    "    line += ' & 0.0 $\\pm$ 0.0'\n",
    "\n",
    "    return line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80d4eab-f013-452b-b4d5-4e0cf8829522",
   "metadata": {},
   "source": [
    "Now do the experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7494082f-89b9-4d90-ae3b-82d42e8f2efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "experiment_names_asha_val_acc = {dataset: [] for dataset in dataset_names}\n",
    "experiment_names_pasha_val_acc_auto = {dataset: [] for dataset in dataset_names}\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    for nb201_random_seed in [0]:\n",
    "        for random_seed in random_seeds:\n",
    "            experiment_name = run_experiment_pd1(dataset_name, random_seed, nb201_random_seed, 'asha', benchmark_metric='metric_valid_error_rate')\n",
    "            experiment_names_asha_val_acc[dataset_name].append((experiment_name, nb201_random_seed))\n",
    "            experiment_name = run_experiment_pd1(dataset_name, random_seed, nb201_random_seed, 'pasha', benchmark_metric='metric_valid_error_rate', rung_system_kwargs={'ranking_criterion': 'soft_ranking_auto', 'epsilon': 0.0})\n",
    "            experiment_names_pasha_val_acc_auto[dataset_name].append((experiment_name, nb201_random_seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "956b9631-68d8-4e05-91a2-6e698acd3484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagenet_resnet_batch_size_512\n",
      "ASHA VACC & 75.10 $\\pm$ 2.03 & 7.3h $\\pm$ 1.2h & 1.0x & 251.0 $\\pm$ 0.0\n",
      "PASHA VACC-AUTO & 73.37 $\\pm$ 2.71 & 3.8h $\\pm$ 1.0h & 1.9x & 45.0 $\\pm$ 30.1\n",
      "One epoch baseline VACC  & 63.40 $\\pm$ 9.91 & 1.1h $\\pm$ 0.0h & 6.7x & 1.0 $\\pm$ 0.0\n",
      "Random baseline  & 35.18 $\\pm$ 31.31 & 0.0h $\\pm$ 0.0h & NA & 0.0 $\\pm$ 0.0\n",
      "translate_wmt_xformer_translate_batch_size_64\n",
      "ASHA VACC & 62.72 $\\pm$ 1.41 & 43.7h $\\pm$ 37.2h & 1.0x & 1357.4 $\\pm$ 80.4\n",
      "PASHA VACC-AUTO & 62.04 $\\pm$ 2.05 & 2.8h $\\pm$ 0.6h & 15.5x & 37.8 $\\pm$ 21.6\n",
      "One epoch baseline VACC  & 62.36 $\\pm$ 1.40 & 0.6h $\\pm$ 0.0h & 67.3x & 1.0 $\\pm$ 0.0\n",
      "Random baseline  & 33.51 $\\pm$ 21.54 & 0.0h $\\pm$ 0.0h & NA & 0.0 $\\pm$ 0.0\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in dataset_names:\n",
    "    print(dataset_name)\n",
    "    result_summary, reference_time = analyse_experiments_pd1(experiment_names_asha_val_acc)\n",
    "    print('ASHA VACC' + result_summary)\n",
    "    result_summary, _ = analyse_experiments_pd1(experiment_names_pasha_val_acc_auto, reference_time)\n",
    "    print('PASHA VACC-AUTO' + result_summary)\n",
    "    result_summary = compute_one_epoch_baseline_pd1(dataset_name)\n",
    "    print('One epoch baseline VACC', result_summary)\n",
    "    result_summary = compute_random_baseline_pd1(dataset_name)\n",
    "    print('Random baseline', result_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f28ba23-1fcb-4ab0-a1ec-1cd599329c90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
